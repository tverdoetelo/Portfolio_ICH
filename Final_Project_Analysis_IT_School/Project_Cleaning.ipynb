{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a05efb4-d02a-42f4-9b87-d16587727551",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "###### Karina Ruban"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4851f18-cc88-4a97-8054-3f273ba436ce",
   "metadata": {},
   "source": [
    "## Task 1. Data cleaning and preparation:\n",
    "##### 1. Remove duplicates and irrelevant columns.\n",
    "##### 2. Process missing values accordingly.\n",
    "##### 3. Convert data types for columns such as dates and numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a332c0-e809-4043-8bce-bd8a4d063c4d",
   "metadata": {},
   "source": [
    "### In this project, the cleaning and data preparation was done according to a certain algorithm to unify the process and make it easier to correct later.\n",
    "#### **Algorithm**:\n",
    "##### 1. Checking and deleting duplicates\n",
    "##### 2. Analysis and processing of missing values\n",
    "##### 3. Converting columns to correct types\n",
    "##### 4. Check for incorrect or illogical values\n",
    "##### 5. ID Uniqueness Check\n",
    "##### 6. Processing of categorical features\n",
    "##### 7. Check for logical consistency\n",
    "##### 8. Creating flags (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3f2dc7-1f4b-4770-8373-2b73ef037520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries & loadibg datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime, time\n",
    "\n",
    "calls_path = 'C:/Users/79607/Documents/Python/tasks/Calls.xlsx'\n",
    "calls = pd.read_excel(calls_path)\n",
    "\n",
    "contacts_path = 'C:/Users/79607/Documents/Python/tasks/Contacts.xlsx'\n",
    "contacts = pd.read_excel(contacts_path)\n",
    "\n",
    "deals_path = 'C:/Users/79607/Documents/Python/tasks/Deals.xlsx'\n",
    "deals = pd.read_excel(deals_path)\n",
    "\n",
    "spend_path = 'C:/Users/79607/Documents/Python/tasks/Spend.xlsx'\n",
    "spend = pd.read_excel(spend_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedadfdd-f205-49d1-ac72-92d49f8a83fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cleaning of dataset Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0822e2d6-82a2-4987-b743-47d2256f2aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95874 entries, 0 to 95873\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Id                          95874 non-null  int64  \n",
      " 1   Call Start Time             95874 non-null  object \n",
      " 2   Call Owner Name             95874 non-null  object \n",
      " 3   CONTACTID                   91941 non-null  float64\n",
      " 4   Call Type                   95874 non-null  object \n",
      " 5   Call Duration (in seconds)  95791 non-null  float64\n",
      " 6   Call Status                 95874 non-null  object \n",
      " 7   Dialled Number              0 non-null      float64\n",
      " 8   Outgoing Call Status        86875 non-null  object \n",
      " 9   Scheduled in CRM            86875 non-null  float64\n",
      " 10  Tag                         0 non-null      float64\n",
      "dtypes: float64(5), int64(1), object(5)\n",
      "memory usage: 8.0+ MB\n",
      "                    Id   Call Start Time Call Owner Name     CONTACTID  \\\n",
      "0  5805028000000805001  30.06.2023 08:43        John Doe           NaN   \n",
      "1  5805028000000768006  30.06.2023 08:46        John Doe           NaN   \n",
      "2  5805028000000764027  30.06.2023 08:59        John Doe           NaN   \n",
      "3  5805028000000787003  30.06.2023 09:20        John Doe  5.805028e+18   \n",
      "4  5805028000000768019  30.06.2023 09:30        John Doe  5.805028e+18   \n",
      "\n",
      "  Call Type  Call Duration (in seconds)       Call Status  Dialled Number  \\\n",
      "0   Inbound                       171.0          Received             NaN   \n",
      "1  Outbound                        28.0  Attended Dialled             NaN   \n",
      "2  Outbound                        24.0  Attended Dialled             NaN   \n",
      "3  Outbound                         6.0  Attended Dialled             NaN   \n",
      "4  Outbound                        11.0  Attended Dialled             NaN   \n",
      "\n",
      "  Outgoing Call Status  Scheduled in CRM  Tag  \n",
      "0                  NaN               NaN  NaN  \n",
      "1            Completed               0.0  NaN  \n",
      "2            Completed               0.0  NaN  \n",
      "3            Completed               0.0  NaN  \n",
      "4            Completed               0.0  NaN  \n"
     ]
    }
   ],
   "source": [
    "# 1. info about dataset Calls & checking structure\n",
    "\n",
    "calls.info()\n",
    "print(calls.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e67db6f-78cf-4c74-967a-2e778159ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming\n",
    "\n",
    "calls.rename(columns={'Id' : 'Calls_ID', 'Call Start Time': 'Call_Start_Time', 'Call Owner Name' : 'Calls_Manager', 'CONTACTID' : 'Contact_ID', 'Call Type' : 'Call_Type', 'Call Duration (in seconds)' : 'Call_Duration_Sec', 'Call Status' : 'Call_Status', 'Outgoing Call Status' : 'Outgoing_Call_Status', 'Scheduled in CRM' : 'Scheduled_In_CRM', 'Dialled Number' : 'Dialled_Number'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95aad00-5a0e-4d00-8133-add32c0ffb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "calls.duplicated().sum() # 0 found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c6e9b6-182f-46bf-bf13-a4b738c7a644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Calls_ID                    0\n",
       "Call_Start_Time             0\n",
       "Calls_Manager               0\n",
       "Contact_ID               3933\n",
       "Call_Type                   0\n",
       "Call_Duration_Sec          83\n",
       "Call_Status                 0\n",
       "Dialled_Number          95874\n",
       "Outgoing_Call_Status     8999\n",
       "Scheduled_In_CRM         8999\n",
       "Tag                     95874\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check for NaN\n",
    "\n",
    "calls.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821017ad-2b85-4cc4-81c3-f5bda0554bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. Evaluate what a pass means & Make a decision:\n",
    "# Contact_ID\n",
    "\n",
    "# some info was missed. ContactID NaN was changed to unique number that belongs nobody to support format and as flag value of not filled cell\n",
    "# this number (0000000000000000000) will add to readme instructions for futher analysis \n",
    "\n",
    "calls['Contact_ID'] = calls['Contact_ID'].fillna(0000000000000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a93e09-b74c-4ee8-8000-8058b4f399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. Evaluate what a pass means & Make a decision:\n",
    "# Call_Duration_Sec\n",
    "\n",
    "# check if the lack of info is related to a certain call status\n",
    "calls_with_nan_duration = calls[calls['Call_Duration_Sec'].isnull()]\n",
    "# print(calls_with_nan_duration['Call_Status'].unique())\n",
    "# print(calls_with_nan_duration['Outgoing_Call_Status'].unique()) \n",
    "\n",
    "# statuses (['Cancelled' 'Overdue' 'Scheduled']) look like there was no calls so duration in fact was 0\n",
    "# this value (0) will add to readme instructions for futher analysis to using, for instance, as flag\n",
    "\n",
    "calls['Call_Duration_Sec'] = calls['Call_Duration_Sec'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ade536-51d5-411d-a732-66e9433d3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3. Evaluate what a pass means & Make a decision:\n",
    "# Dialled_Number & Tag\n",
    "\n",
    "# the whole columns are empty --> delete\n",
    "\n",
    "calls.drop(columns=['Dialled_Number','Tag'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805df9a1-853e-4981-bd49-a4659c760c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4. Evaluate what a pass means & Make a decision:\n",
    "# Outgoing_Call_Status\n",
    "\n",
    "# check if the lack of info is related to a certain call status\n",
    "outgoing_call_status_calls = calls[calls['Outgoing_Call_Status'].isnull()]\n",
    "# print(outgoing_call_status_calls['Call_Type'].unique())\n",
    "\n",
    "# this NaNs are correct because this calls were not outbounds.\n",
    "# status inbound or smth else in this column is illogical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "844e6b37-b0b4-4b94-83a4-e0e187a9ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5. Evaluate what a pass means & Make a decision:\n",
    "# Scheduled_In_CRM \n",
    "\n",
    "# check if the lack of info is related to a certain call status\n",
    "scheduled_calls = calls[calls['Scheduled_In_CRM'] == True]\n",
    "# print(scheduled_calls['Call_Status'].unique())\n",
    "# print(scheduled_calls['Outgoing_Call_Status'].unique())\n",
    "\n",
    "nan_calls = calls[calls['Scheduled_In_CRM'].isnull()]\n",
    "# print(nan_calls['Call_Status'].unique())\n",
    "# print(nan_calls['Outgoing_Call_Status'].unique())\n",
    "\n",
    "# statuses ['Received' 'Missed'] are different but no 'scheduled' status means in fact not scheduled --> 0 (not scheduled)\n",
    "calls['Scheduled_In_CRM'] = calls['Scheduled_In_CRM'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5398fb99-baf8-41f3-8e25-2cc2e98cb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Converting columns to correct types\n",
    "\n",
    "#Dates\n",
    "calls['Call_Start_Time'] = pd.to_datetime(calls['Call_Start_Time'], errors='coerce', dayfirst=True)\n",
    "\n",
    "#Strings\n",
    "calls['Calls_ID'] = calls['Calls_ID'].astype(str)\n",
    "calls['Contact_ID'] = calls['Contact_ID'].astype(str)\n",
    "\n",
    "#Numbers\n",
    "calls['Call_Duration_Sec'] = calls['Call_Duration_Sec'].astype(int)\n",
    "\n",
    "#Boolean\n",
    "calls['Scheduled_In_CRM'] = calls['Scheduled_In_CRM'].astype(bool)\n",
    "\n",
    "#Categories\n",
    "calls_categorical_columns = ['Calls_Manager', 'Call_Type', 'Call_Status', 'Outgoing_Call_Status']\n",
    "for col in calls_categorical_columns:\n",
    "    calls[col] = calls[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35c55ed-025f-4f5c-84fe-6098f8842c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls_Manager\n",
      "Yara Edwards       9059\n",
      "Julia Nelson       7446\n",
      "Ian Miller         7215\n",
      "Charlie Davis      7213\n",
      "Diana Evans        6857\n",
      "Ulysses Adams      6085\n",
      "Amy Green          5982\n",
      "Nina Scott         5581\n",
      "Victor Barnes      5439\n",
      "Kevin Parker       5406\n",
      "Paula Underwood    4580\n",
      "Quincy Vincent     4384\n",
      "Jane Smith         3753\n",
      "Cara Iverson       3300\n",
      "John Doe           2986\n",
      "Ben Hall           2947\n",
      "Alice Johnson      1251\n",
      "Mason Roberts      1166\n",
      "Derek James         948\n",
      "George King         850\n",
      "Zachary Foster      523\n",
      "Eva Kent            498\n",
      "Fiona Jackson       470\n",
      "Sam Young           457\n",
      "Rachel White        441\n",
      "Xander Dean         304\n",
      "Ethan Harris        280\n",
      "Hannah Lee          175\n",
      "Wendy Clark         162\n",
      "Bob Brown            99\n",
      "Oliver Taylor        10\n",
      "Tina Zhang            5\n",
      "Laura Quinn           2\n",
      "Name: count, dtype: int64\n",
      "Call_Type\n",
      "Outbound    86875\n",
      "Missed       5921\n",
      "Inbound      3078\n",
      "Name: count, dtype: int64\n",
      "Call_Status\n",
      "Attended Dialled              70703\n",
      "Unattended Dialled            16030\n",
      "Missed                         5922\n",
      "Received                       3077\n",
      "Overdue                          60\n",
      "Scheduled Attended Delay         22\n",
      "Cancelled                        20\n",
      "Scheduled Unattended Delay       17\n",
      "Scheduled Attended               14\n",
      "Scheduled Unattended              6\n",
      "Scheduled                         3\n",
      "Name: count, dtype: int64\n",
      "Outgoing_Call_Status\n",
      "Completed    86792\n",
      "Overdue         60\n",
      "Cancelled       20\n",
      "Scheduled        3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4.1. Check for incorrect or illogical values\n",
    "# deleting spaces & checking mistypes in categories\n",
    "\n",
    "# just for info to check mistypes. for thousands of unique values other methods are needed, at least creating a dict and checking with it\n",
    "for col in calls_categorical_columns:\n",
    "    print(calls[col].value_counts()) \n",
    "    \n",
    "for col in calls_categorical_columns:\n",
    "    if calls[col].dtype == 'category':\n",
    "        calls[col] = calls[col].str.strip()\n",
    "        calls[col] = calls[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c26e2fc-3825-465c-9b2c-450e8f6eba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Check for incorrect or illogical values\n",
    "# check for negative values in call duration\n",
    "\n",
    "negative_call_duration = calls[calls['Call_Duration_Sec'] < 0]\n",
    "# if not negative_call_duration.empty:\n",
    "#     print(f'Found {len(negative_duration)}calls with negative call duration')\n",
    "# else:\n",
    "#     print('Negative call duration not found') # Negative call duration not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754588ef-d9cf-46ec-9dcc-3328fab18b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3. Check for incorrect or illogical values\n",
    "# check for calls in future\n",
    "\n",
    "future_calls = calls[calls['Call_Start_Time'] > datetime.now()]\n",
    "# if not future_calls.empty:\n",
    "#     print(f'Found {len(future_calls)} call with dates in future')\n",
    "# else:\n",
    "#     print('No future call dates found') # No future call dates found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e072cf1c-082b-4abd-b1ee-e07415f5da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Authentication of unique id\n",
    "\n",
    "total_calls_rows = len(calls)\n",
    "unique_calls_ids = calls['Calls_ID'].nunique()\n",
    "\n",
    "# if total_calls_rows == unique_calls_ids:\n",
    "#     print('All ID calls are unique')\n",
    "# else:\n",
    "#     print(f'Found duplicates in ID calls. Number of duplicates: {total_calls_rows - unique_calls_ids}') # All ID calls are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab2de7c-7f3f-4e0c-b7d9-de51f1ee6502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Received', 'Dialled', 'Missed', 'Cancelled', 'Unattended', 'Overdue', 'Delay', 'Attended', 'Scheduled']\n",
      "Categories (9, object): ['Attended', 'Cancelled', 'Delay', 'Dialled', ..., 'Overdue', 'Received', 'Scheduled', 'Unattended']\n"
     ]
    }
   ],
   "source": [
    "# 6. Categorical feature processing\n",
    "# Reducing categories to the last status as actual\n",
    "\n",
    "calls['Call_Status'] = calls['Call_Status'].str.split().str[-1]\n",
    "calls['Call_Status'] = calls['Call_Status'].astype('category')\n",
    "print(calls['Call_Status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9f773c7-b2a8-4a1a-9344-8d3708d07322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Check for logical consistency\n",
    "# Check that inbounds has not outgoing status\n",
    "\n",
    "inbound_with_outgoing_status = calls[(calls['Call_Type'] == 'Inbound')&(calls['Outgoing_Call_Status'].notna())]\n",
    "\n",
    "# if not inbound_with_outgoing_status.empty:\n",
    "#     print(f'Found {len(inbound_with_outgoing_status)} incoming calls with outgoing call status')\n",
    "# else:\n",
    "#     print('Incoming calls do not have outbound status. Logical consistency is respected') # Incoming calls do not have outbound status. Logical consistency is respected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e17b3e8-75ac-4ffd-8a21-be665ab4ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95874 entries, 0 to 95873\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Calls_ID              95874 non-null  object        \n",
      " 1   Call_Start_Time       95874 non-null  datetime64[ns]\n",
      " 2   Calls_Manager         95874 non-null  category      \n",
      " 3   Contact_ID            95874 non-null  object        \n",
      " 4   Call_Type             95874 non-null  category      \n",
      " 5   Call_Duration_Sec     95874 non-null  int32         \n",
      " 6   Call_Status           95874 non-null  category      \n",
      " 7   Outgoing_Call_Status  86875 non-null  category      \n",
      " 8   Scheduled_In_CRM      95874 non-null  bool          \n",
      "dtypes: bool(1), category(4), datetime64[ns](1), int32(1), object(2)\n",
      "memory usage: 3.0+ MB\n",
      "              Calls_ID     Call_Start_Time Calls_Manager  \\\n",
      "0  5805028000000805001 2023-06-30 08:43:00      John Doe   \n",
      "1  5805028000000768006 2023-06-30 08:46:00      John Doe   \n",
      "2  5805028000000764027 2023-06-30 08:59:00      John Doe   \n",
      "3  5805028000000787003 2023-06-30 09:20:00      John Doe   \n",
      "4  5805028000000768019 2023-06-30 09:30:00      John Doe   \n",
      "\n",
      "              Contact_ID Call_Type  Call_Duration_Sec Call_Status  \\\n",
      "0                    0.0   Inbound                171    Received   \n",
      "1                    0.0  Outbound                 28     Dialled   \n",
      "2                    0.0  Outbound                 24     Dialled   \n",
      "3  5.805028000000645e+18  Outbound                  6     Dialled   \n",
      "4  5.805028000000645e+18  Outbound                 11     Dialled   \n",
      "\n",
      "  Outgoing_Call_Status  Scheduled_In_CRM  \n",
      "0                  NaN             False  \n",
      "1            Completed             False  \n",
      "2            Completed             False  \n",
      "3            Completed             False  \n",
      "4            Completed             False  \n"
     ]
    }
   ],
   "source": [
    "# check info about dataset Calls & structure after cleaning & prep\n",
    "\n",
    "calls.info()\n",
    "print(calls.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0cbcc-ffc4-4e43-b78f-49119e130ed1",
   "metadata": {},
   "source": [
    "## Cleanig of dataset Contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71a41c40-a44f-4520-bf5f-b3c161c0f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18548 entries, 0 to 18547\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Id                  18548 non-null  int64 \n",
      " 1   Contact Owner Name  18548 non-null  object\n",
      " 2   Created Time        18548 non-null  object\n",
      " 3   Modified Time       18548 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 579.8+ KB\n",
      "                    Id Contact Owner Name      Created Time     Modified Time\n",
      "0  5805028000000645014       Rachel White  27.06.2023 11:28  22.12.2023 13:34\n",
      "1  5805028000000872003      Charlie Davis  03.07.2023 11:31  21.05.2024 10:23\n",
      "2  5805028000000889001          Bob Brown  02.07.2023 22:37  21.12.2023 13:17\n",
      "3  5805028000000907006          Bob Brown  03.07.2023 05:44  29.12.2023 15:20\n",
      "4  5805028000000939010         Nina Scott  04.07.2023 10:11  16.04.2024 16:14\n"
     ]
    }
   ],
   "source": [
    "# 1. info about dataset Contacts & checking structure\n",
    "\n",
    "contacts.info()\n",
    "print(contacts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4005ab9d-d443-4e57-b9cc-f4d678b60a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming\n",
    "\n",
    "contacts.rename(columns={'Id' : 'Contacts_ID', 'Contact Owner Name' : 'Contacts_Manager', 'Created Time' : 'Created_Time', 'Modified Time' : 'Modified_Time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e23d25d-4a5e-4a7c-a9ec-9d11c89f3c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for duplicates\n",
    "\n",
    "contacts.duplicated().sum() # 0 found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70180b22-2b0b-4831-b190-0982f67421dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contacts_ID         0\n",
       "Contacts_Manager    0\n",
       "Created_Time        0\n",
       "Modified_Time       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check for NaN\n",
    "\n",
    "contacts.isnull().sum() # 0 found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb7515b4-ed64-4407-80f7-eae9e4fd3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Converting columns to correct types\n",
    "\n",
    "# Category\n",
    "contacts['Contacts_Manager'] = contacts['Contacts_Manager'].astype('category')\n",
    "\n",
    "# String\n",
    "contacts['Contacts_ID'] = contacts['Contacts_ID'].astype(str)\n",
    "\n",
    "# Dates\n",
    "contacts['Created_Time'] = pd.to_datetime(contacts['Created_Time'], errors='coerce', dayfirst=True)\n",
    "contacts['Modified_Time'] = pd.to_datetime(contacts['Modified_Time'], errors='coerce', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ad40c6c-e3bb-449d-90c3-9052627b1ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contacts_Manager\n",
      "Charlie Davis      2018\n",
      "Ulysses Adams      1816\n",
      "Julia Nelson       1769\n",
      "Paula Underwood    1487\n",
      "Quincy Vincent     1416\n",
      "Nina Scott         1150\n",
      "Ben Hall           1038\n",
      "Victor Barnes       967\n",
      "Cara Iverson        880\n",
      "Rachel White        782\n",
      "Jane Smith          754\n",
      "Bob Brown           685\n",
      "Ian Miller          684\n",
      "Diana Evans         678\n",
      "Yara Edwards        655\n",
      "Amy Green           621\n",
      "Eva Kent            365\n",
      "Kevin Parker        325\n",
      "Mason Roberts       217\n",
      "George King         144\n",
      "Sam Young            37\n",
      "Alice Johnson        27\n",
      "Oliver Taylor        19\n",
      "Zachary Foster        8\n",
      "Wendy Clark           2\n",
      "Tina Zhang            2\n",
      "Derek James           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4.1. Check for incorrect or illogical values\n",
    "# deleting spaces & checking mistypes in categories\n",
    "\n",
    "contacts['Contacts_Manager'] = contacts['Contacts_Manager'].str.strip()\n",
    "print(contacts['Contacts_Manager'].value_counts()) #just for info to check mistypes. not optimal for billions rows. in future dict may be used not to check all values, only new ones\n",
    "\n",
    "contacts.isnull().sum()\n",
    "\n",
    "# probably one value was \" \" (just space)\n",
    "contacts['Contacts_Manager'] = contacts['Contacts_Manager'].fillna('Unknown')\n",
    "contacts['Contacts_Manager'] = contacts['Contacts_Manager'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "739b63f7-beef-4954-951e-2bb4f07cc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Check for incorrect or illogical values\n",
    "# check for dates\n",
    "\n",
    "invalid_dates = contacts[contacts['Modified_Time'] < contacts['Created_Time']]\n",
    "\n",
    "# if not invalid_dates.empty:\n",
    "#     print(f'Found {len(invalid_dates)} invalid dates')\n",
    "# else:\n",
    "#     print('All dates are valid') # All dates are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19ebd282-0777-43e9-b319-e41c095c6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Authentication of unique id\n",
    "\n",
    "total_contacts_rows = len(contacts)\n",
    "unique_contacts_ids = contacts['Contacts_ID'].nunique()\n",
    "\n",
    "# if total_contacts_rows == unique_contacts_ids:\n",
    "#     print('All ID contacts are unique')\n",
    "# else:\n",
    "#     print(f'Found duplicates in ID contacts. Number of duplicates: {total_contacts_rows - unique_contacts_ids}') # All ID contacts are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f73cc319-bd2d-4c9b-acbe-25e478321647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18548 entries, 0 to 18547\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Contacts_ID       18548 non-null  object        \n",
      " 1   Contacts_Manager  18548 non-null  category      \n",
      " 2   Created_Time      18548 non-null  datetime64[ns]\n",
      " 3   Modified_Time     18548 non-null  datetime64[ns]\n",
      "dtypes: category(1), datetime64[ns](2), object(1)\n",
      "memory usage: 454.2+ KB\n",
      "           Contacts_ID Contacts_Manager        Created_Time  \\\n",
      "0  5805028000000645014     Rachel White 2023-06-27 11:28:00   \n",
      "1  5805028000000872003    Charlie Davis 2023-07-03 11:31:00   \n",
      "2  5805028000000889001        Bob Brown 2023-07-02 22:37:00   \n",
      "3  5805028000000907006        Bob Brown 2023-07-03 05:44:00   \n",
      "4  5805028000000939010       Nina Scott 2023-07-04 10:11:00   \n",
      "\n",
      "        Modified_Time  \n",
      "0 2023-12-22 13:34:00  \n",
      "1 2024-05-21 10:23:00  \n",
      "2 2023-12-21 13:17:00  \n",
      "3 2023-12-29 15:20:00  \n",
      "4 2024-04-16 16:14:00  \n"
     ]
    }
   ],
   "source": [
    "# check info about dataset Contacts & structure after cleaning & prep\n",
    "\n",
    "contacts.info()\n",
    "print(contacts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fa338-e4f9-40f6-b521-0f8522edb09f",
   "metadata": {},
   "source": [
    "## Cleaning of dataset Deals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf551c33-587c-4250-9539-d11cd3184894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21595 entries, 0 to 21594\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Id                   21593 non-null  float64\n",
      " 1   Deal Owner Name      21564 non-null  object \n",
      " 2   Closing Date         14645 non-null  object \n",
      " 3   Quality              19340 non-null  object \n",
      " 4   Stage                21593 non-null  object \n",
      " 5   Lost Reason          16124 non-null  object \n",
      " 6   Page                 21593 non-null  object \n",
      " 7   Campaign             16067 non-null  object \n",
      " 8   SLA                  15533 non-null  object \n",
      " 9   Content              14147 non-null  object \n",
      " 10  Term                 12454 non-null  object \n",
      " 11  Source               21593 non-null  object \n",
      " 12  Payment Type         496 non-null    object \n",
      " 13  Product              3592 non-null   object \n",
      " 14  Education Type       3300 non-null   object \n",
      " 15  Created Time         21593 non-null  object \n",
      " 16  Course duration      3587 non-null   float64\n",
      " 17  Months of study      840 non-null    float64\n",
      " 18  Initial Amount Paid  4165 non-null   object \n",
      " 19  Offer Total Amount   4185 non-null   object \n",
      " 20  Contact Name         21532 non-null  float64\n",
      " 21  City                 2511 non-null   object \n",
      " 22  Level of Deutsch     1251 non-null   object \n",
      "dtypes: float64(4), object(19)\n",
      "memory usage: 3.8+ MB\n",
      "             Id Deal Owner Name Closing Date            Quality     Stage  \\\n",
      "0  5.805028e+18        Ben Hall          NaN                NaN  New Lead   \n",
      "1  5.805028e+18   Ulysses Adams          NaN                NaN  New Lead   \n",
      "2  5.805028e+18   Ulysses Adams   21.06.2024     D - Non Target      Lost   \n",
      "3  5.805028e+18        Eva Kent   21.06.2024  E - Non Qualified      Lost   \n",
      "4  5.805028e+18        Ben Hall   21.06.2024     D - Non Target      Lost   \n",
      "\n",
      "      Lost Reason       Page                  Campaign       SLA  \\\n",
      "0             NaN  /eng/test             03.07.23women       NaN   \n",
      "1             NaN    /at-eng                       NaN       NaN   \n",
      "2      Non target    /at-eng                engwien_AT  00:26:43   \n",
      "3  Invalid number       /eng  04.07.23recentlymoved_DE  01:00:04   \n",
      "4      Non target       /eng              discovery_DE  00:53:12   \n",
      "\n",
      "              Content  ...        Product Education Type      Created Time  \\\n",
      "0                 v16  ...            NaN            NaN  21.06.2024 15:30   \n",
      "1                 NaN  ...  Web Developer        Morning  21.06.2024 15:23   \n",
      "2               b1-at  ...            NaN            NaN  21.06.2024 14:45   \n",
      "3  bloggersvideo14com  ...            NaN            NaN  21.06.2024 13:32   \n",
      "4             website  ...            NaN            NaN  21.06.2024 13:21   \n",
      "\n",
      "  Course duration Months of study Initial Amount Paid  Offer Total Amount  \\\n",
      "0             NaN             NaN                 NaN                 NaN   \n",
      "1             6.0             NaN                   0                2000   \n",
      "2             NaN             NaN                 NaN                 NaN   \n",
      "3             NaN             NaN                 NaN                 NaN   \n",
      "4             NaN             NaN                 NaN                 NaN   \n",
      "\n",
      "   Contact Name City Level of Deutsch  \n",
      "0  5.805028e+18  NaN              NaN  \n",
      "1  5.805028e+18  NaN              NaN  \n",
      "2  5.805028e+18  NaN              NaN  \n",
      "3  5.805028e+18  NaN              NaN  \n",
      "4  5.805028e+18  NaN              NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. info about dataset Deals & checking structure\n",
    "\n",
    "deals.info()\n",
    "print(deals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d0a8922-4bdd-4c2a-9856-639023071e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming\n",
    "\n",
    "deals.rename(columns={'Id' : 'Deals_ID', 'Deal Owner Name' : 'Deals_Manager', 'Closing Date' : 'Closing_Date', 'Lost Reason' : 'Lost_Reason', 'Campaign' : 'Deals_Campaign', 'Payment Type' : 'Payment_Type', 'Education Type' : 'Education_Type', 'Created Time' : 'Created_Time', 'Course duration' : 'Course_Duration', 'Months of study' : 'Months_Of_Study', 'Initial Amount Paid' : 'Initial_Amount_Paid', 'Offer Total Amount' : 'Offer_Total_Amount', 'Contact Name' : 'Contact_Name', 'Level of Deutsch' : 'Level_Of_German'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c12fe18-c08b-4e33-ae10-7847acb651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "# deals.duplicated().sum() #3 duplicates\n",
    "deals = deals.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23a7763c-31f1-4494-92a0-aa3f8f11c3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deals_ID                   2\n",
       "Deals_Manager             31\n",
       "Closing_Date            6949\n",
       "Quality                 2254\n",
       "Stage                      2\n",
       "Lost_Reason             5470\n",
       "Page                       2\n",
       "Deals_Campaign          5526\n",
       "SLA                     6059\n",
       "Content                 7446\n",
       "Term                    9139\n",
       "Source                     2\n",
       "Payment_Type           21096\n",
       "Product                18000\n",
       "Education_Type         18292\n",
       "Created_Time               2\n",
       "Course_Duration        18005\n",
       "Months_Of_Study        20752\n",
       "Initial_Amount_Paid    17427\n",
       "Offer_Total_Amount     17407\n",
       "Contact_Name              63\n",
       "City                   19081\n",
       "Level_Of_German        20341\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check for NaN\n",
    "\n",
    "deals.isnull().sum()\n",
    "# Closing_Date wiil kepp like that because it may mean that deal was not closed for any reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f8b8d43-24ce-4748-935c-9c4e2ab2155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. Evaluate what a pass means & Make a decision:\n",
    "# Deals_ID is a key metric --> delete rows without\n",
    "\n",
    "deals = deals.dropna(subset=['Deals_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5892236b-b643-4d7e-a8ba-4ff396abe48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. Evaluate what a pass means & Make a decision:\n",
    "# Contact_Name is a key metric (ID) --> delete rows without\n",
    "\n",
    "deals = deals.dropna(subset=['Contact_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65cf9f56-dee4-421a-920a-eb23eb888cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3. Evaluate what a pass means & Make a decision:\n",
    "# Deals_Manager for unknown reasons is unknown --> unknown. \n",
    "# now impossible to say if it is important to keep or not\n",
    "\n",
    "deals['Deals_Manager'] = deals['Deals_Manager'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f15dd3b-0ae6-4083-9d76-2138037d1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4. Evaluate what a pass means & Make a decision:\n",
    "# Quality \n",
    "\n",
    "# print(deals['Quality'].unique())\n",
    "\n",
    "# check if the lack of info is related to a certain stage or even lost reason\n",
    "\n",
    "quality_nan_deals = deals[deals['Quality'].str.strip().isna()]\n",
    "# print(quality_nan_deals['Stage'].unique())\n",
    "# print(quality_nan_deals['Lost_Reason'].unique())\n",
    "\n",
    "# there is no pattern --> change to Unknown\n",
    "\n",
    "deals['Quality'] = deals['Quality'].fillna('G - Unknown')\n",
    "\n",
    "# Quality F is also not clear qithout any comments. \n",
    "# check if the lack of info is related to a certain stage or even lost reason to explain the meaning\n",
    "\n",
    "quality_f_deals = deals[deals['Quality'].str.strip() == 'F']\n",
    "# if not quality_f_deals.empty:\n",
    "#     print(f'Found {len(quality_f_deals)} deals with Quality F')\n",
    "# else:\n",
    "#     print('Deals with Quality F not found')\n",
    "# print(quality_f_deals['Stage'].unique())\n",
    "# print(quality_f_deals['Lost_Reason'].unique())\n",
    "\n",
    "# there is no pattern --> combine 3 F deals with other not clear statuses (G - Unknown) & rename to F\n",
    "deals['Quality'] = deals['Quality'].replace('F', 'G - Unknown')\n",
    "deals['Quality'] = deals['Quality'].replace('G - Unknown', 'F - Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b76d144c-f77d-4199-9882-515201d2f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5. Evaluate what a pass means & Make a decision:\n",
    "# Lost_Reason \n",
    "\n",
    "# print(deals['Lost_Reason'].unique())\n",
    "\n",
    "# check if the lack of info is related to a certain stage\n",
    "\n",
    "deals_nan_lost_reason = deals[deals['Lost_Reason'].isnull()]\n",
    "# print(deals_nan_lost_reason['Stage'].unique())\n",
    "\n",
    "# some NaNs are correct because deals were not lost. For lost deals input \"unknown\" reason\n",
    "\n",
    "deals.loc[(deals['Stage'].str.strip() == 'Lost') & (deals['Lost_Reason'].isnull()), 'Lost_Reason'] = 'Unknown'\n",
    "\n",
    "# From FAQ\n",
    "# Question: There is a \"Lost Reason\" column and it takes the following values. As I understand it, the duplicate indicates that the transaction was simply tampered with in the system?\n",
    "# Answer: Yes, it means the leds were two and in 1 is worth a lot just because it is a duplicate\n",
    "\n",
    "deals = deals[deals['Lost_Reason'] != 'Duplicate']\n",
    "\n",
    "# categories will be combined later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6dca569-0f4e-4233-ab05-0f631f1556f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6. Evaluate what a pass means & Make a decision:\n",
    "# Campaign \n",
    "\n",
    "# print(deals['Deals_Campaign'].unique()) #not really informative\n",
    "deals['Deals_Campaign'] = deals['Deals_Campaign'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d19371c2-7dd8-4204-91a0-69312e60bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7. Evaluate what a pass means & Make a decision:\n",
    "# SLA \n",
    "# many troubles because of formats\n",
    "# conversion to string hh:mm:s\n",
    "\n",
    "new_SLA = []\n",
    "\n",
    "for value in deals['SLA']:\n",
    "    if isinstance(value, (time, datetime)):\n",
    "        new_SLA.append(value.strftime('%H:%M:%S'))\n",
    "    else:\n",
    "        new_SLA.append(value)\n",
    "    \n",
    "deals['SLA'] = new_SLA\n",
    "\n",
    "# SLA may depend on the manager. In the absence of information, empty blanks are filled with mode for all data\n",
    "\n",
    "mode_SLA = deals.loc[deals['SLA'].notnull(), 'SLA'].mode()\n",
    "\n",
    "if mode_SLA.empty:\n",
    "    mode_SLA = '00:00:00'\n",
    "else:\n",
    "    mode_SLA = mode_SLA[0]\n",
    "\n",
    "for manager in deals['Deals_Manager'].unique():\n",
    "    manager_data = deals[deals['Deals_Manager'] == manager]\n",
    "    manager_mode_SLA = manager_data.loc[manager_data['SLA'].notnull(), 'SLA'].mode()\n",
    "    \n",
    "    if not manager_mode_SLA.empty:\n",
    "        mode_to_fill = manager_mode_SLA[0]\n",
    "    else:\n",
    "        mode_to_fill = mode_SLA\n",
    "    \n",
    "    deals.loc[(deals['Deals_Manager'] == manager) & (deals['SLA'].isnull()), 'SLA'] = mode_to_fill\n",
    "\n",
    "# conversion to date\n",
    "\n",
    "deals['SLA'] = pd.to_timedelta(deals['SLA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "163e367f-aa0c-43fe-afbd-44173566ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8. Evaluate what a pass means & Make a decision:\n",
    "# Content\n",
    "\n",
    "# print(deals['Content'].unique())\n",
    "deals['Content'] = deals['Content'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e78b0cca-5156-4cb2-9c71-0d13f042cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.9. Evaluate what a pass means & Make a decision:\n",
    "# Term\n",
    "\n",
    "# print(deals['Term'].unique())\n",
    "deals['Term'] = deals['Term'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e687966-c9f5-4414-ab6c-333257adaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.10. Evaluate what a pass means & Make a decision:\n",
    "# Payment_Type\n",
    "\n",
    "# check if the lack of info is related to a certain stage\n",
    "\n",
    "# print(deals['Payment_Type'].unique())\n",
    "payment_type_nan = deals[deals['Payment_Type'].isnull()]\n",
    "nan_payment_stages = payment_type_nan['Stage'].value_counts(dropna=False)\n",
    "# print(nan_payment_stages)\n",
    "\n",
    "# lost deals have no payments so NaN is logical value. for other add 'Unknown'\n",
    "\n",
    "deals.loc[(deals['Stage'].str.strip() != 'Lost') & (deals['Payment_Type'].isnull()), 'Payment_Type'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6c88ebf-f8f0-4458-bb22-747fa7f997c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.11. Evaluate what a pass means & Make a decision:\n",
    "# Product\n",
    "\n",
    "# print(deals['Product'].unique())\n",
    "deals['Product'] = deals['Product'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfd9b728-323e-4906-8e96-ad4e8676ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.12. Evaluate what a pass means & Make a decision:\n",
    "# Education_Type\n",
    "\n",
    "# print(deals['Education_Type'].unique())\n",
    "\n",
    "# check if the lack of info is related to a certain product\n",
    "\n",
    "filled_product_education_type = deals[deals['Education_Type'].notna() & deals['Product'].notna()]\n",
    "correlation_product_education_type = filled_product_education_type.groupby(['Product', 'Education_Type']).size().unstack(fill_value=0)\n",
    "# print(correlation_product_education_type)\n",
    "\n",
    "nan_product_education_type = deals[deals['Education_Type'].isnull()]['Product'].value_counts(dropna=False)\n",
    "# print(nan_product_education_type)\n",
    "\n",
    "# according to products add mode education type\n",
    "\n",
    "deals['Education_Type'] = deals.groupby('Product')['Education_Type'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "\n",
    "# the rest will be Unknown\n",
    "\n",
    "deals['Education_Type'] = deals['Education_Type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ee8ec70-2b5a-46ff-b562-ad6f13facde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  6. 11.]\n"
     ]
    }
   ],
   "source": [
    "# 2.13. Evaluate what a pass means & Make a decision:\n",
    "# Course_Duration\n",
    "\n",
    "print(deals['Course_Duration'].unique())\n",
    "\n",
    "# check if the lack of info is related to a certain product\n",
    "\n",
    "filled_product_course_duration = deals[deals['Course_Duration'].notna() & deals['Product'].notna()]\n",
    "correlation_product_course_duration = filled_product_course_duration.groupby(['Product', 'Course_Duration']).size().unstack(fill_value=0)\n",
    "# print(correlation_product_course_duration)\n",
    "\n",
    "nan_product_course_duration = deals[deals['Course_Duration'].isnull()]['Product'].value_counts(dropna=False)\n",
    "# print(nan_product_course_duration)\n",
    "\n",
    "# if prodict is unknown, there is no duration\n",
    "\n",
    "deals.loc[(deals['Product'] == 'Unknown') & (deals['Course_Duration'].isnull()), 'Course_Duration'] = 0\n",
    "\n",
    "# according to products add mode course duration\n",
    "\n",
    "deals['Course_Duration'] = deals.groupby('Product')['Course_Duration'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "\n",
    "# the rest is unknown but for support format will be 0\n",
    "\n",
    "deals['Course_Duration'] = deals['Course_Duration'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2dac2773-d6e1-41cb-9c24-cfada9483493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  1.  0.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      "Months_Of_Study  0.0   1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0   \\\n",
      "Stage                                                                         \n",
      "Payment Done        1    65   104    94    93    64   102    78    81    61   \n",
      "\n",
      "Months_Of_Study  10.0  11.0  \n",
      "Stage                        \n",
      "Payment Done       42    45  \n",
      "Stage\n",
      "Lost                         13967\n",
      "Call Delayed                  2236\n",
      "Registered on Webinar         2069\n",
      "Waiting For Payment            324\n",
      "Qualificated                   128\n",
      "Registered on Offline Day       85\n",
      "Need to Call - Sales            33\n",
      "Need To Call                    31\n",
      "Test Sent                       25\n",
      "Need a consultation             23\n",
      "Payment Done                    16\n",
      "New Lead                         5\n",
      "Free Education                   1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2.14. Evaluate what a pass means & Make a decision:\n",
    "# Months_Of_Study\n",
    "\n",
    "print(deals['Months_Of_Study'].unique())\n",
    "\n",
    "# check if the lack of info is related to a certain Stage\n",
    "\n",
    "filled_stage_months = deals[deals['Months_Of_Study'].notna() & deals['Stage'].notna()]\n",
    "correlation_stage_months = filled_stage_months.groupby(['Stage', 'Months_Of_Study']).size().unstack(fill_value=0)\n",
    "print(correlation_stage_months)\n",
    "\n",
    "nan_stage_months = deals[deals['Months_Of_Study'].isnull()]['Stage'].value_counts(dropna=False)\n",
    "print(nan_stage_months)\n",
    "\n",
    "# for stage \"payment done\" add mode month. for others Nan is ok because they were lost or did not start.\n",
    "# for non-historical data, the month of study can be calculated with now()\n",
    "\n",
    "deals.loc[(deals['Stage'] == 'Payment Done') & (deals['Months_Of_Study'].isnull()), 'Months_Of_Study'] = deals.loc[deals['Stage'] == 'Payment Done', 'Months_Of_Study'].mode()[0]\n",
    "\n",
    "# still refilled less than 5% of rows --> drop the column because this amount is not enough to use\n",
    "\n",
    "deals = deals.drop('Months_Of_Study', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f5a8697-cdf6-40fa-b5fa-0e8e46b797a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.15. Evaluate what a pass means & Make a decision:\n",
    "# Initial_Amount_Paid\n",
    "\n",
    "# print(deals['Initial_Amount_Paid'].unique())\n",
    "\n",
    "# strings were found\n",
    "\n",
    "deals['Initial_Amount_Paid'] = deals['Initial_Amount_Paid'].astype(str).str.replace('€ ', '', regex=False)\n",
    "deals['Initial_Amount_Paid'] = deals['Initial_Amount_Paid'].str.replace('.', '', regex=False)\n",
    "deals['Initial_Amount_Paid'] = deals['Initial_Amount_Paid'].str.replace(',', '.', regex=False)\n",
    "\n",
    "# print(deals['Initial_Amount_Paid'].unique())\n",
    "\n",
    "# string 'nan' was found\n",
    "\n",
    "deals['Initial_Amount_Paid'] = deals['Initial_Amount_Paid'].astype(str).str.lower().str.strip().replace('nan', np.nan)\n",
    "deals['Initial_Amount_Paid'] = pd.to_numeric(deals['Initial_Amount_Paid'], errors='coerce')\n",
    "\n",
    "# all have different conditions --> not enough info to refill but to support format will add flag as 1000000\n",
    "\n",
    "deals['Initial_Amount_Paid'] = deals['Initial_Amount_Paid'].fillna(1000000)\n",
    "\n",
    "# print(deals['Initial_Amount_Paid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a35678e-d83a-436f-ac76-b15e5cd51ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.16. Evaluate what a pass means & Make a decision:\n",
    "# Offer_Total_Amount\n",
    "\n",
    "# print(deals['Offer_Total_Amount'].unique())\n",
    "\n",
    "# found strings\n",
    "\n",
    "deals['Offer_Total_Amount'] = deals['Offer_Total_Amount'].astype(str).str.replace('€ ', '', regex=False)\n",
    "deals['Offer_Total_Amount'] = deals['Offer_Total_Amount'].str.replace('.', '', regex=False)\n",
    "deals['Offer_Total_Amount'] = deals['Offer_Total_Amount'].str.replace(',', '.', regex=False)\n",
    "\n",
    "# print(deals['Offer_Total_Amount'].unique())\n",
    "\n",
    "# string 'nan' was found\n",
    "\n",
    "deals['Offer_Total_Amount'] = deals['Offer_Total_Amount'].astype(str).str.lower().str.strip().replace('nan', np.nan)\n",
    "deals['Offer_Total_Amount'] = pd.to_numeric(deals['Offer_Total_Amount'], errors='coerce')\n",
    "\n",
    "# add mode to NaN if product is known\n",
    "\n",
    "unique_products = deals['Product'].dropna().unique()\n",
    "for product in unique_products:\n",
    "    product_group = deals.loc[deals['Product'] == product, 'Offer_Total_Amount']\n",
    "    if not product_group.mode().empty:\n",
    "        mode_val = product_group.mode().iloc[0]\n",
    "        deals.loc[deals['Product'] == product, 'Offer_Total_Amount'] = deals.loc[deals['Product'] == product, 'Offer_Total_Amount'].fillna(mode_val)\n",
    "\n",
    "# for unknown products not enough info to refill but to support format will add flag as 1000000\n",
    "\n",
    "deals['Offer_Total_Amount'] = deals['Offer_Total_Amount'].fillna(1000000)\n",
    "\n",
    "# print(deals['Offer_Total_Amount'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d370383a-0298-4f93-b0c6-6a91c2e1bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.17. Evaluate what a pass means & Make a decision:\n",
    "# City\n",
    "\n",
    "# print(deals['City'].unique())\n",
    "\n",
    "deals['City'] = deals['City'].fillna('Unknown')\n",
    "\n",
    "# cleaning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9afb2b2d-a73c-4b4c-89c6-8df45d3941ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.18. Evaluate what a pass means & Make a decision:\n",
    "# Level_Of_German\n",
    "\n",
    "# print(deals['Level_Of_German'].unique())\n",
    "\n",
    "deals['Level_Of_German'] = deals['Level_Of_German'].fillna('Unknown')\n",
    "\n",
    "# cleaning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34580cd4-38f6-4c7f-b01a-8cad8650161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Converting columns to correct types\n",
    "\n",
    "# numbers\n",
    "deals['Deals_ID'] = deals['Deals_ID'].astype(str)\n",
    "deals['Contact_Name'] = deals['Contact_Name'].astype(str)\n",
    "deals['Initial_Amount_Paid'] = deals['Initial_Amount_Paid'].astype(int)\n",
    "deals['Offer_Total_Amount'] = deals['Offer_Total_Amount'].astype(int)\n",
    "deals['Course_Duration'] = deals['Course_Duration'].astype(int)\n",
    "\n",
    "# dates\n",
    "deals['Closing_Date'] = pd.to_datetime(deals['Closing_Date'], errors='coerce', dayfirst=True)\n",
    "deals['Created_Time'] = pd.to_datetime(deals['Created_Time'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# categories\n",
    "deals_categorical_columns = ['Deals_Manager', 'Quality', 'Stage', 'Lost_Reason', 'Page', 'Source', 'Payment_Type', 'Product', 'Education_Type', 'City', 'Level_Of_German']\n",
    "for col in deals_categorical_columns:\n",
    "    deals[col] = deals[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94dcaf9a-f1a7-4287-b86f-e345378903ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Check for incorrect or illogical values\n",
    "# deleting spaces in categories\n",
    "\n",
    "for col in deals_categorical_columns:\n",
    "    if deals[col].dtype == 'category':\n",
    "        deals[col] = deals[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba3173d0-d7d9-4a93-af9b-157c697b9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Check for incorrect or illogical values\n",
    "# check for negative values in course duration\n",
    "\n",
    "negative_course_duration = deals[deals['Course_Duration'] < 0]\n",
    "# if not negative_course_duration.empty:\n",
    "#     print(f'Found {len(negative_duration)} cases with negative course duration')\n",
    "# else:\n",
    "#     print('Cases with negative course duration not found') # Cases with negative course duration not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90018181-6b49-4f50-bbaf-de179e389dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dates are valid\n"
     ]
    }
   ],
   "source": [
    "# 4.3. Check for incorrect or illogical values\n",
    "# check for dates\n",
    "\n",
    "deals_invalid_dates = deals[deals['Created_Time'] < deals['Closing_Date']]\n",
    "if not invalid_dates.empty:\n",
    "    print(f'Found {len(deals_invalid_dates)} invalid dates')\n",
    "else:\n",
    "    print('All dates are valid') # All dates are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "347e7325-b2af-493d-ae69-52ee978d35f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15788 invalid amounts\n"
     ]
    }
   ],
   "source": [
    "# 4.3. Check for incorrect or illogical values\n",
    "# check for payments\n",
    "\n",
    "deals_invalid_amounts = deals[deals['Offer_Total_Amount'] < deals['Initial_Amount_Paid']]\n",
    "if not deals_invalid_amounts.empty:\n",
    "    print(f'Found {len(deals_invalid_amounts)} invalid amounts')\n",
    "    deals.loc[deals['Initial_Amount_Paid'] > deals['Offer_Total_Amount'], 'Initial_Amount_Paid'] = deals['Offer_Total_Amount']\n",
    "else:\n",
    "    print('All amounts are valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b242ee3-16f5-4f79-aa81-c63b7117c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found duplicates in ID deals. Number of duplicates: 11480\n",
      "Found duplicates in contact names. Number of duplicates: 11939\n"
     ]
    }
   ],
   "source": [
    "# 5. Authentication of unique id\n",
    "\n",
    "total_deals_rows = len(deals)\n",
    "unique_deals_ids = deals['Deals_ID'].nunique()\n",
    "\n",
    "if total_deals_rows == unique_deals_ids:\n",
    "    print('All ID deals are unique')\n",
    "else:\n",
    "    print(f'Found duplicates in ID deals. Number of duplicates: {total_deals_rows - unique_deals_ids}') # Found duplicates in ID deals. Number of duplicates: 11480\n",
    "\n",
    "total_deals_rows = len(deals)\n",
    "unique_deals_contacts = deals['Contact_Name'].nunique()\n",
    "\n",
    "if total_deals_rows == unique_deals_contacts:\n",
    "    print('All contact names are unique')\n",
    "else:\n",
    "    print(f'Found duplicates in contact names. Number of duplicates: {total_deals_rows - unique_deals_contacts}') # Found duplicates in contact names. Number of duplicates: 11939\n",
    "\n",
    "# contact could buy several courses, fill in applications from different sources\n",
    "# duplicate deals may occur due to recording each time in the data system when changing, for example, stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59dcf894-d798-4697-8301-5d1e62f222f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6.1. Categorical feature processing\n",
    "# Reducing number of categories\n",
    "# Lost_Reason \n",
    "\n",
    "# print(deals['Lost_Reason'].unique())\n",
    "\n",
    "category_mapping = {'Expensive': 'Financial Reasons', 'The contract did not fit': 'Financial Reasons', 'Gutstein refusal': 'Financial Reasons', 'Thought for free': 'Financial Reasons',\n",
    "                    'Inadequate': 'Skill Issues', 'Does not know how to use a computer': 'Skill Issues', 'Does not speak English': 'Skill Issues',\n",
    "                    \"Doesn't Answer\": 'No Response', 'Stopped Answering': 'No Response',\n",
    "                    'needs time to think': 'Personal Issues', 'Not for myself': 'Personal Issues', 'Conditions are not suitable': 'Personal Issues',\n",
    "                    'Considering a different direction in IT': 'Refusal', 'Changed Decision': 'Refusal', \"Didn't leave an application\": 'Refusal', 'Went to Rivals': 'Refusal',\n",
    "                    'Invalid number': 'Technical Issues', \n",
    "                    'Non target': 'Other', 'Refugee': 'Other', 'Next stream': 'Other', 'Unknown': 'Other'}\n",
    "\n",
    "deals['Lost_Reason_Combined'] = deals['Lost_Reason'].map(category_mapping)\n",
    "\n",
    "# print(deals['Lost_Reason_combined'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98309a26-264f-429d-8629-20a5ea66cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2. Categorical feature processing\n",
    "# Reducing number of categories\n",
    "# Stage \n",
    "\n",
    "# print(deals['Stage'].unique())\n",
    "\n",
    "category_stage_mapping = {'New Lead': 'New Lead', \n",
    "                          'Need a consultation': 'In Progress', 'Need to Call': 'In Progress', 'Need to Call - Sales': 'In Progress', \n",
    "                          'Call Delayed': 'In Progress', 'Qualificated': 'In Progress', 'Registered on Webinar': 'In Progress',\n",
    "                          'Test Sent': 'In Progress', 'Registered on Offline Day': 'In Progress', 'Free Education': 'In Progress',\n",
    "                          'Lost': 'Lost',\n",
    "                          'Waiting For Payment': 'Waiting For Payment',\n",
    "                          'Payment Done': 'Payment Done'}\n",
    "\n",
    "deals['Stage_Combined'] = deals['Stage'].map(category_stage_mapping)\n",
    "\n",
    "# print(deals['Stage_Сombined'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21ae4114-f214-4880-9bd9-a82948c3e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3. Categorical feature processing\n",
    "# City cleaning\n",
    "\n",
    "# print(deals['City'].unique())\n",
    "\n",
    "deals['City'] = deals['City'].replace('-', 'Unknown')\n",
    "deals.loc[deals['City'].str.contains(r'\\d', na=False), 'City'] = 'Unknown' #remove any complicated data with numbers\n",
    "deals.loc[deals['City'].str.contains(',', na=False), 'City'] = 'Unknown' #remove any complicated data with unnecessary info\n",
    "deals['City'] = deals['City'].str.replace(r'\\(.*?\\)', '', regex=True) #remove any complicated data with unnecessary info\n",
    "\n",
    "# with increasing amount of the data at least with each next stream, role of mistypes will increasse too. \n",
    "# there is universal solution is needed such as special library\n",
    "# long (~20-30 mins) process but is worth it\n",
    "\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "geokey_API = '5bfa60fd7b464d17b3031543f79ba9aa'\n",
    "geocoder = OpenCageGeocode(geokey_API) # free source\n",
    "\n",
    "city_cache = {} #create dict to save time&memory\n",
    "\n",
    "def normalize_city(city_name):\n",
    "    if city_name in city_cache:\n",
    "        return city_cache[city_name]\n",
    "    location = geocoder.geocode(city_name, language='en')\n",
    "    normilized_city_name = 'Unknown'\n",
    "    if location and len(location) > 0:\n",
    "        normilized_city_name = location[0]['components'].get('city', 'Unknown')\n",
    "        if normilized_city_name == 'Unknown':\n",
    "            normilized_city_name = location[0]['components'].get('town', 'Unknown')\n",
    "                \n",
    "    city_cache[city_name] = normilized_city_name\n",
    "    return normilized_city_name\n",
    "\n",
    "deals['City'] = deals['City'].apply(normalize_city)\n",
    "\n",
    "# due to different languagues, there is many non standard letters that are not avaliable for everyone\n",
    "# now may be kept\n",
    "# better use universal solution as library to avoid problems with special symbols\n",
    "\n",
    "import unidecode\n",
    "\n",
    "deals['City'] = deals['City'].str.lower()\n",
    "\n",
    "deals['City'] = deals['City'].apply(unidecode.unidecode) #special library that changed non standard to the most suitable standard symbol\n",
    "deals['City'] = deals['City'].str.replace(r'[^a-zа-я\\s]', ' ', regex=True).str.strip() #remove any other symbols\n",
    "\n",
    "deals['City'] = deals['City'].str.capitalize()\n",
    "\n",
    "# print(deals['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1854f9a7-403f-4078-a7c8-8ee7d31f8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4. Categorical feature processing\n",
    "# Level_Of_German cleaning\n",
    "\n",
    "# print(deals['Level_Of_German'].unique())\n",
    "\n",
    "# sometimes there is info together about german&english. decided to keep as a true with %%probability of mistake.\n",
    "# especially because people sometimes evaluate their level independently also with error\n",
    "\n",
    "deals['Level_Of_German'] = np.where(deals['Level_Of_German'].str.contains(r'[12]', na=False), deals['Level_Of_German'],'Unknown')\n",
    "\n",
    "deals.loc[deals['Level_Of_German'] != 'Unknown', 'Level_Of_German'] = deals.loc[deals['Level_Of_German'] != 'Unknown', 'Level_Of_German'].str.lower()\n",
    "deals.loc[deals['Level_Of_German'] != 'Unknown', 'Level_Of_German'] = deals.loc[deals['Level_Of_German'] != 'Unknown', 'Level_Of_German'].str.replace('а', 'a').str.replace('f', 'a').str.replace('в', 'b').str.replace('б', 'b').str.replace('с', 'c')\n",
    "deals.loc[deals['Level_Of_German'] != 'Unknown', 'Level_Of_German'] = deals.loc[deals['Level_Of_German'] != 'Unknown', 'Level_Of_German'].str.extract(r'([abc][12](?:\\-[abc][12])?)', expand=False)\n",
    "deals['Level_Of_German'] = deals['Level_Of_German'].fillna('Unknown')\n",
    "\n",
    "# print(deals['Level_Of_German'].unique()) # b2-c2 level found\n",
    "\n",
    "deals.loc[deals['Level_Of_German'] == 'b2-c2', 'Level_Of_German'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f840b6d1-e13d-4619-948e-4c0079210726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5. Categorical feature processing\n",
    "\n",
    "deals_categorical_columns = ['Deals_Manager', 'Deals_Campaign', 'Quality', 'Stage', 'Stage_Combined', 'Lost_Reason_Combined', 'Lost_Reason', 'Page', 'Source', 'Payment_Type', 'Product', 'Education_Type', 'City', 'Level_Of_German']\n",
    "for col in deals_categorical_columns:\n",
    "    deals[col] = deals[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05c0b0e4-273c-4348-91be-f63e324b8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Creating flags \n",
    "\n",
    "deals['Is_Deal_Lost'] = (deals['Stage'] == 'Lost')\n",
    "\n",
    "deals['Is_Payment_Done'] = (deals['Stage'] == 'Payment Done')\n",
    "\n",
    "deals['Is_Initial_Payment_Missig'] = (deals['Stage'] == 'Payment Done')&(deals['Initial_Amount_Paid'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0cb97da-ece6-47b5-9b3a-a3b67c62bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19773 entries, 0 to 21592\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype          \n",
      "---  ------                     --------------  -----          \n",
      " 0   Deals_ID                   19773 non-null  object         \n",
      " 1   Deals_Manager              19773 non-null  category       \n",
      " 2   Closing_Date               13105 non-null  datetime64[ns] \n",
      " 3   Quality                    19773 non-null  category       \n",
      " 4   Stage                      19773 non-null  category       \n",
      " 5   Lost_Reason                14368 non-null  category       \n",
      " 6   Page                       19773 non-null  category       \n",
      " 7   Deals_Campaign             19773 non-null  category       \n",
      " 8   SLA                        19773 non-null  timedelta64[ns]\n",
      " 9   Content                    19773 non-null  object         \n",
      " 10  Term                       19773 non-null  object         \n",
      " 11  Source                     19773 non-null  category       \n",
      " 12  Payment_Type               5906 non-null   category       \n",
      " 13  Product                    19773 non-null  category       \n",
      " 14  Education_Type             19773 non-null  category       \n",
      " 15  Created_Time               19773 non-null  datetime64[ns] \n",
      " 16  Course_Duration            19773 non-null  int32          \n",
      " 17  Initial_Amount_Paid        19773 non-null  int32          \n",
      " 18  Offer_Total_Amount         19773 non-null  int32          \n",
      " 19  Contact_Name               19773 non-null  object         \n",
      " 20  City                       19773 non-null  category       \n",
      " 21  Level_Of_German            19773 non-null  category       \n",
      " 22  Lost_Reason_Combined       14368 non-null  category       \n",
      " 23  Stage_Combined             19742 non-null  category       \n",
      " 24  Is_Deal_Lost               19773 non-null  bool           \n",
      " 25  Is_Payment_Done            19773 non-null  bool           \n",
      " 26  Is_Initial_Payment_Missig  19773 non-null  bool           \n",
      "dtypes: bool(3), category(14), datetime64[ns](2), int32(3), object(4), timedelta64[ns](1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# check info about dataset Deals & structure after cleaning & prep\n",
    "\n",
    "deals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83061cc2-5d30-49e4-b812-4dd7be6b3c1b",
   "metadata": {},
   "source": [
    "## Cleanig of dataset Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71e3b6c4-8a53-48bd-9adf-1848b8e2dc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20779 entries, 0 to 20778\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Date         20779 non-null  datetime64[ns]\n",
      " 1   Source       20779 non-null  object        \n",
      " 2   Campaign     14785 non-null  object        \n",
      " 3   Impressions  20779 non-null  int64         \n",
      " 4   Spend        20779 non-null  float64       \n",
      " 5   Clicks       20779 non-null  int64         \n",
      " 6   AdGroup      13951 non-null  object        \n",
      " 7   Ad           13951 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(4)\n",
      "memory usage: 1.3+ MB\n",
      "        Date        Source               Campaign  Impressions  Spend  Clicks  \\\n",
      "0 2023-07-03    Google Ads         gen_analyst_DE            6   0.00       0   \n",
      "1 2023-07-03    Google Ads  performancemax_eng_DE            4   0.01       1   \n",
      "2 2023-07-03  Facebook Ads                    NaN            0   0.00       0   \n",
      "3 2023-07-03    Google Ads                    NaN            0   0.00       0   \n",
      "4 2023-07-03           CRM                    NaN            0   0.00       0   \n",
      "\n",
      "  AdGroup   Ad  \n",
      "0     NaN  NaN  \n",
      "1     NaN  NaN  \n",
      "2     NaN  NaN  \n",
      "3     NaN  NaN  \n",
      "4     NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "# 1. info about dataset Spend & checking structure\n",
    "\n",
    "spend.info()\n",
    "print(spend.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb99a978-0519-4970-a7cf-aed046b8658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming\n",
    "\n",
    "spend.rename(columns={'Source' : 'Spend_Source', 'Campaign' : 'Spend_Campaign', 'AdGroup' : 'Ad_Group'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87d3b619-b85c-420d-9e72-b154a14b9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "# spend.duplicated().sum()  #917 duplicates\n",
    "spend = spend.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63624ac8-fa05-48e2-90bc-9c7cc4b92847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Spend_Source         0\n",
       "Spend_Campaign    5077\n",
       "Impressions          0\n",
       "Spend                0\n",
       "Clicks               0\n",
       "Ad_Group          5911\n",
       "Ad                5911\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check for NaN\n",
    "\n",
    "spend.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aed3101b-b690-4402-8a18-256a8bad756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. Evaluate what a pass means & Make a decision:\n",
    "# Spend_Campaign\n",
    "\n",
    "# print(spend['Spend_Campaign'].unique())\n",
    "\n",
    "# not enough info to add \"valuable values\"\n",
    "\n",
    "spend['Spend_Campaign'] = spend['Spend_Campaign'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80f6487c-d002-4030-8f2e-78029e3bb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. Evaluate what a pass means & Make a decision:\n",
    "# Ad_Group\n",
    "\n",
    "# print(spend['Ad_Group'].unique())\n",
    "\n",
    "# not enough info to add \"valuable values\"\n",
    "\n",
    "spend['Ad_Group'] = spend['Ad_Group'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c1c0f54-031d-44bb-b155-a353f4c49681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'b3' 'b1' 'b4' 'b2' 'v2' 'v1' 'b4com' 'b3com' 'b2com' 'b1com' 'v6com'\n",
      " 'v5' 'v4com' 'v3com' 'v5com' 'ad4' 'ad1' 'ad2' 'ad3' 'v8com' 'v7com'\n",
      " 'ad6' 'ad5' 'bloggersvideo1com' 'v9com' 'ad9' 'ad8' 'ad_blogger_1'\n",
      " 'ad_blogger_2' 'ad7' 'web_b3' 'web_b5' 'web_b1' 'web_b4' 'web_b2'\n",
      " 'ad_blogger_3' 'v10com' 'bloggersvideo2com' 'b5' 'b6' 'b8' 'b7' 'v3'\n",
      " 'v10' 'v12' 'v11com' 'v11' 'ad_gov_1' 'ad_da_1' 'b3comwebdev'\n",
      " 'bloggersvideo2comwebdev' 'v11comwebdev' 'b1comwebdev' 'b2comwebdev'\n",
      " 'bloggersvideo4com' 'bloggersvideo3com' 'bloggersvideo5' 'promo2'\n",
      " 'promo1' 'ad_blogger_4' 'bloggersvideo4' 'b10' 'b11' 'b12' 'ad_blogger_6'\n",
      " 'promo3' 'b15blackfriday' 'b14blackfriday' 'b13blackfriday' 'b7webinar'\n",
      " 'b6webinar' 'b4webinar' 'b5webinar' 'bloggersvideo6blackfriday'\n",
      " 'bloggersvideo6webinar' 'bloggersvideo7blackfriday'\n",
      " 'bloggersvideo7webinar' 'bloggersvideo8webinar' 'v7blackfriday'\n",
      " 'b9offlinewebinar' 'b10offlinewebinar' 'b8offlinewebinar'\n",
      " 'bloggersvideo9com' 'bloggersvideo5com' 'bloggersvideo8com' 'b1de'\n",
      " 'bloggersvideo11' 'bloggersvideo10' 'b3de' 'b4de' 'b2de' 'b3webdesigner'\n",
      " 'b1python-developer' 'b1qa-engineer' 'b3python-developer'\n",
      " 'b4python-developer' 'b1webdesigner' 'b4qa-engineer' 'b3qa-engineer'\n",
      " 'b2webdesigner' 'b2qa-engineer' 'b2python-developer' 'promo4'\n",
      " 'bloggersvideo10com_python' 'v12com_python' 'v13com_python'\n",
      " 'bloggersvideo1python' 'bloggersvideo2python' 'bloggersvideo3python'\n",
      " 'v1webinar' 'v2webinar' 'v14com - unactual' 'v16com' 'v15com' 'v3webinar'\n",
      " 'v14com' 'v14' 'bloggersvideo11 - unactual' 'v15' 'v16'\n",
      " 'bloggersvideo12com_at' 'v3com_at' 'v14com_at' 'bloggersvideo13'\n",
      " 'bloggersvideo17com' 'bloggersvideo15com' 'bloggersvideo16com'\n",
      " 'Austria_video3' 'bloggersvideo15com_python' 'bloggersvideo1'\n",
      " 'bloggersvideo14com' 'Austria_video2' 'Austria_video1' 'v3com_pl'\n",
      " 'v14com_pl' 'bloggersvideo12com_pl' 'video1com_new' 'bloggersvideo10com'\n",
      " 'poland_video2' 'bloggervideo1' 'bloggervideo2' 'poland_video1'\n",
      " 'v15com_pl' 'bloggersvideo8com_pl' 'bloggersvideo16com_pl'\n",
      " 'bloggersvideo18com_pl' 'v5webinar' 'bloggersvideo18webinar' 'v4webinar'\n",
      " 'bloggersvideo19com_pl' 'bloggersvideo21com_pl' 'bloggersvideo20com_pl'\n",
      " 'v17com_pl' 'b1accountant' 'b3accountant' 'b2accountant' 'b4accountant'\n",
      " 'bloggersvideo19com' 'bloggersvideo22com' 'bloggersvideo16com_at'\n",
      " 'bloggersvideo18com' 'bloggersvideo12com' 'bloggersvideo24com'\n",
      " 'bloggersvideo23' 'v6webinar' 'bloggersvideo18webinar_new' 'v7webinar'\n",
      " 'bloggersvideo1webinar' 'bloggersvideo2webinar' 'bloggersvideo1june'\n",
      " 'bloggersvideo25com' 'bloggersvideo23com' 'bloggersvideo2june' 'v18com'\n",
      " 'bloggersvideo20com' 'bloggersvideo3june']\n"
     ]
    }
   ],
   "source": [
    "# 2.3. Evaluate what a pass means & Make a decision:\n",
    "# Ad\n",
    "\n",
    "print(spend['Ad'].unique())\n",
    "\n",
    "# not enough info to add \"valuable values\"\n",
    "\n",
    "spend['Ad'] = spend['Ad'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd0a293c-1353-4bbd-beb2-5033e2a32c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Converting columns to correct types\n",
    "\n",
    "categorical_columns_spend = ['Spend_Source', 'Spend_Campaign']\n",
    "for col in categorical_columns_spend:\n",
    "    spend[col] = spend[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80e476b2-90cb-4e34-a3f8-925fb45fbcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend_Source\n",
      "Facebook Ads      9569\n",
      "Tiktok Ads        2985\n",
      "Youtube Ads       1784\n",
      "Google Ads        1266\n",
      "Telegram posts     836\n",
      "Webinar            766\n",
      "Bloggers           632\n",
      "SMM                571\n",
      "Organic            514\n",
      "CRM                355\n",
      "Test               262\n",
      "Partnership        234\n",
      "Offline             61\n",
      "Radio               27\n",
      "Name: count, dtype: int64\n",
      "Spend_Campaign\n",
      "Unknown                        5077\n",
      "12.07.2023wide_DE              2073\n",
      "02.07.23wide_DE                1685\n",
      "04.07.23recentlymoved_DE       1398\n",
      "youtube_shorts_DE              1223\n",
      "07.07.23LAL_DE                 1181\n",
      "03.07.23women                  1171\n",
      "12.09.23interests_Uxui_DE      1143\n",
      "15.07.23b_DE                    529\n",
      "24.09.23retargeting_DE          504\n",
      "performancemax_eng_DE           355\n",
      "20.03.2024wide_PL               240\n",
      "30.11.23wide_DE                 233\n",
      "05.07.23interests_DE            214\n",
      "17.03.24wide_AT                 198\n",
      "07.12.23test_DE                 176\n",
      "20.03.24interests_WebDev_PL     169\n",
      "discovery_DE                    166\n",
      "brand_search_eng_DE             146\n",
      "youtube_shortsin_AT             133\n",
      "08.04.24wide_webinar_DE         133\n",
      "20.05.24interests_DE            130\n",
      "20.03.24_widde_PL               129\n",
      "15.03.2024wide_AT               111\n",
      "15.11.23wide_webinar_DE         107\n",
      "01.04.23women_PL                103\n",
      "performancemax_wide_AT           93\n",
      "05.09.2023wide_DE                88\n",
      "18.10.23wide_gos_DE              80\n",
      "web2408_DE                       76\n",
      "shorts_PL                        73\n",
      "22.05.2024wide_DE                60\n",
      "24.07.2023wide_DE                58\n",
      "20.03.24interests_WebDev_AT      57\n",
      "14.11.23wide_webinar_DE          56\n",
      "1performancemax_wide_PL          49\n",
      "gen_analyst_DE                   48\n",
      "09.02.24berlin_dd_DE             48\n",
      "10.07.23wide_com_DE              45\n",
      "discovery_wide1_AT               44\n",
      "08.06.24wide_webinar_DE          44\n",
      "15.04.24LAL_ab__PL               39\n",
      "02.08.23interests_DE             36\n",
      "15.03.24recentlymoved_AT         35\n",
      "12.06.24wide_DE                  29\n",
      "20.05.24wide_DE                  21\n",
      "02.05.24test_DE                  21\n",
      "01.02.24wide_webinar_DE          16\n",
      "20.03.24recentlymoved_PL          9\n",
      "comp_search_DE                    8\n",
      "bbo_DE                            1\n",
      "blog2_DE                          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4.1. Check for incorrect or illogical values\n",
    "# checking mistypes in categories\n",
    "\n",
    "for col in categorical_columns_spend:\n",
    "    print(spend[col].value_counts()) # just for info to check mistypes. for thousands of unique values other methods are needed, at least creating a dict and checking with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "760dbe09-e495-45d9-8415-fb0c69b8686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Check for incorrect or illogical values\n",
    "# check for negative values in spend\n",
    "\n",
    "negative_spend = spend[spend['Spend'] < 0]\n",
    "\n",
    "# if not negative_spend.empty:\n",
    "#     print(f'Found {len(negative_spend)} cases with negative spends')\n",
    "# else:\n",
    "#     print('Negative spends not found') # Negative spends not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dbbc6cf5-86ad-4e5e-b0c7-3f0aef9b822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3. Check for incorrect or illogical values\n",
    "# check for negative values in clicks\n",
    "\n",
    "negative_clicks = spend[spend['Clicks'] < 0]\n",
    "\n",
    "# if not negative_clicks.empty:\n",
    "#     print(f'Found {len(negative_clicks)} cases with negative clicks')\n",
    "# else:\n",
    "#     print('Negative clicks not found') # Negative clicks not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0244b0a0-56af-4fb8-b64f-c9500aaf3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4. Check for incorrect or illogical values\n",
    "# check for negative values in impressions\n",
    "\n",
    "negative_impressions = spend[spend['Impressions'] < 0]\n",
    "\n",
    "# if not negative_impressions.empty:\n",
    "#     print(f'Found {len(negative_impressions)} cases with negative impressions')\n",
    "# else:\n",
    "#     print('Negative impressions not found') # Negative impressions not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be3d243d-e9a3-4d23-898c-6a06394cbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Creating flags \n",
    "\n",
    "spend['Is_Campaign_Unknown'] = (spend['Spend_Campaign'] == 'Unknown')\n",
    "        \n",
    "spend['Is_Spend_For_No_Clicks'] = (spend['Clicks'] == 0) & (spend['Spend'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c48b028-a3e1-4a43-b6cf-8e1fb0ce26eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19862 entries, 0 to 20778\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Date                    19862 non-null  datetime64[ns]\n",
      " 1   Spend_Source            19862 non-null  category      \n",
      " 2   Spend_Campaign          19862 non-null  category      \n",
      " 3   Impressions             19862 non-null  int64         \n",
      " 4   Spend                   19862 non-null  float64       \n",
      " 5   Clicks                  19862 non-null  int64         \n",
      " 6   Ad_Group                19862 non-null  object        \n",
      " 7   Ad                      19862 non-null  object        \n",
      " 8   Is_Campaign_Unknown     19862 non-null  bool          \n",
      " 9   Is_Spend_For_No_Clicks  19862 non-null  bool          \n",
      "dtypes: bool(2), category(2), datetime64[ns](1), float64(1), int64(2), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# check info about dataset Spend & structure after cleaning & prep\n",
    "\n",
    "spend.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c8a3c27b-a1f6-4918-9ccb-6ea209845f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export with keeping all set formats\n",
    "\n",
    "cleaned_project_data = [calls, contacts, deals, spend]\n",
    "\n",
    "with open('cleaned_project_data.pickle', 'wb') as f:\n",
    "    pickle.dump(cleaned_project_data, f)\n",
    "\n",
    "# with open(\"data.pickle\", \"rb\") as f:\n",
    "#     calls, contacts, deals, spend = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
